{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "91bb50f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T12:26:43.511788Z",
     "start_time": "2022-03-11T12:26:03.145092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downloading pretrained embedding model.\n",
      "this may take a while...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import gensim.downloader\n",
    "import gensim\n",
    "import re\n",
    "from typing import Optional\n",
    "import swifter\n",
    "from PythonCode.preprocess.common import load_data\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, GRU, AvgPool1D\n",
    "from keras.models import Sequential\n",
    "from sklearn.metrics import classification_report\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "print(\"downloading pretrained embedding model.\\nthis may take a while...\")\n",
    "glove_vectors = gensim.downloader.load('glove-wiki-gigaword-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97edf3a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T12:57:09.464930Z",
     "start_time": "2022-03-11T12:57:09.457931Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "NUM_OF_SENTENCE_CHUNK = 3\n",
    "MAX_LENGTH = 170\n",
    "TEST_PART = 0.1\n",
    "VALIDATION_PART = 0.1\n",
    "MAX_SENTENCE_LENGTH = 70\n",
    "MAX_NUMBER_OF_SENTENCE = 45\n",
    "DATA_PATH = \"../Data/C50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f4e6a19f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T12:58:28.425155Z",
     "start_time": "2022-03-11T12:58:28.382238Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Masking\n",
    "\n",
    "def tranform_word(word: str) -> Optional[np.ndarray]:\n",
    "    word = re.sub(r'[^a-z]', '', word.lower())\n",
    "    if word in glove_vectors:\n",
    "        return glove_vectors[word]\n",
    "    return None\n",
    "\n",
    "\n",
    "def complex_tranform_word(word: str):\n",
    "    result = tranform_word(word)\n",
    "    if result is None:\n",
    "        token = lemmatizer.lemmatize(word)\n",
    "        if token in glove_vectors:\n",
    "            return glove_vectors[token]\n",
    "        token = stemmer.stem(word)\n",
    "        if token in glove_vectors:\n",
    "            return glove_vectors[token]\n",
    "    return result\n",
    "\n",
    "\n",
    "def pad_matrix(arr: np.ndarray, max_length: int) -> Optional[np.ndarray]:\n",
    "    if arr.size == 0:\n",
    "        return None\n",
    "    if arr.shape[0] == max_length:\n",
    "        return arr\n",
    "    if arr.shape[0] > max_length:\n",
    "        return arr[:max_length, :]\n",
    "    return np.concatenate([arr, np.zeros((max_length - arr.shape[0], arr.shape[1]))], axis=0, dtype=float)\n",
    "\n",
    "\n",
    "def get_datasets(data_path: str = \"../Data/C50\") -> pd.DataFrame:\n",
    "    df_test = load_data(f\"{data_path}/C50test\", 50)\n",
    "    df_train = load_data(f\"{data_path}/C50train\", 50)\n",
    "    return df_train.append(df_test, ignore_index=True)\n",
    "\n",
    "\n",
    "def preprocess_labels(y: pd.Series) -> np.ndarray:\n",
    "    y_codes = pd.Categorical(y).codes\n",
    "    one_hot = tf.keras.utils.to_categorical(\n",
    "        y_codes, num_classes=pd.Series(y_codes).unique().size, dtype='float32'\n",
    "    )\n",
    "    return np.expand_dims(one_hot, axis=1)\n",
    "\n",
    "\n",
    "def pad_array(arr: np.ndarray, pad_size: int):  # TODO: reuse pad_matrix instead\n",
    "    if arr.size == pad_size:\n",
    "        return arr\n",
    "    elif arr.size > pad_size:\n",
    "        return arr[:pad_size, ]\n",
    "    return np.concatenate([arr, np.zeros(pad_size - arr.size)], dtype=float)\n",
    "\n",
    "\n",
    "def article_level_preprocess_helper(text: str):\n",
    "    sentences = nltk.sent_tokenize(text)\n",
    "    result = []\n",
    "    for sentence in sentences:\n",
    "        words = nltk.word_tokenize(sentence)\n",
    "        curr_result = []\n",
    "        for word in words:\n",
    "            embedding = tranform_word(word)\n",
    "            if embedding is not None:\n",
    "                curr_result.append(embedding)\n",
    "        if len(curr_result) != 0:\n",
    "            result.append(pad_array(np.array(curr_result, dtype=float).mean(axis=1, dtype=float), MAX_SENTENCE_LENGTH))\n",
    "    return pad_matrix(np.array(result), MAX_NUMBER_OF_SENTENCE)\n",
    "\n",
    "\n",
    "def article_level_preprocess(df: pd.DataFrame):\n",
    "    def helper(X):\n",
    "        res = X.swifter.apply(article_level_preprocess_helper).reset_index(drop=True)\n",
    "        return np.vstack(res).reshape((res.size, MAX_NUMBER_OF_SENTENCE, MAX_SENTENCE_LENGTH))\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[\"book_text\"], df[\"author_name\"], test_size=TEST_PART)\n",
    "    return helper(X_train), helper(X_test), preprocess_labels(y_train), preprocess_labels(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dae5feb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T12:28:14.789911Z",
     "start_time": "2022-03-11T12:27:30.631988Z"
    }
   },
   "outputs": [],
   "source": [
    "df = get_datasets(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "db0e0ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T12:59:53.886601Z",
     "start_time": "2022-03-11T12:58:31.445106Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f441d30bd37141468c3864843484d3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/4500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944b871818cb42daa4bcc5f4bda6ac54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Pandas Apply:   0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = article_level_preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "26950d08",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T13:08:00.272815Z",
     "start_time": "2022-03-11T13:07:59.954031Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "masking_5 (Masking)          (None, 45, 70)            0         \n",
      "_________________________________________________________________\n",
      "gru_5 (GRU)                  (None, 45, 200)           163200    \n",
      "_________________________________________________________________\n",
      "average_pooling1d_5 (Average (None, 1, 200)            0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1, 50)             10050     \n",
      "=================================================================\n",
      "Total params: 173,250\n",
      "Trainable params: 173,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Masking(mask_value=0., input_shape=(MAX_NUMBER_OF_SENTENCE, MAX_SENTENCE_LENGTH)))\n",
    "model.add(GRU(200,recurrent_dropout=0.2,return_sequences=True,recurrent_regularizer=tf.keras.regularizers.l1_l2(l1=0.001,l2=0.001)))\n",
    "model.add(AvgPool1D(pool_size=(MAX_NUMBER_OF_SENTENCE,)))\n",
    "model.add(Dense(50, activation=\"softmax\"))#kernel_regularizer= tf.keras.regularizers.l1_l2(l1=0.001,l2=0.001)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccbab9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=VALIDATION_PART)\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=30)\n",
    "model_name = \"article_based_model\"\n",
    "# model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f\"./{model_name}-checkpoints\",\n",
    "#                                                                save_weights_only=False,\n",
    "#                                                                monitor='val_accuracy', mode='max',\n",
    "#                                                                save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f368279c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-03-11T13:19:45.556932Z",
     "start_time": "2022-03-11T13:08:14.749007Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "127/127 [==============================] - 18s 113ms/step - loss: 4.7897 - accuracy: 0.0343 - val_loss: 3.8910 - val_accuracy: 0.0600\n",
      "Epoch 2/50\n",
      "127/127 [==============================] - 13s 106ms/step - loss: 3.8288 - accuracy: 0.0506 - val_loss: 3.7767 - val_accuracy: 0.0533\n",
      "Epoch 3/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.7433 - accuracy: 0.0578 - val_loss: 3.7295 - val_accuracy: 0.0667\n",
      "Epoch 4/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.7002 - accuracy: 0.0691 - val_loss: 3.7012 - val_accuracy: 0.0711\n",
      "Epoch 5/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.6665 - accuracy: 0.0778 - val_loss: 3.6713 - val_accuracy: 0.0822\n",
      "Epoch 6/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.6322 - accuracy: 0.0844 - val_loss: 3.6427 - val_accuracy: 0.0956\n",
      "Epoch 7/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.6000 - accuracy: 0.1044 - val_loss: 3.6098 - val_accuracy: 0.1044\n",
      "Epoch 8/50\n",
      "127/127 [==============================] - 13s 106ms/step - loss: 3.5730 - accuracy: 0.1064 - val_loss: 3.5923 - val_accuracy: 0.1067\n",
      "Epoch 9/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.5455 - accuracy: 0.1190 - val_loss: 3.5705 - val_accuracy: 0.1044\n",
      "Epoch 10/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.5203 - accuracy: 0.1262 - val_loss: 3.5548 - val_accuracy: 0.1022\n",
      "Epoch 11/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.5022 - accuracy: 0.1343 - val_loss: 3.5361 - val_accuracy: 0.1000\n",
      "Epoch 12/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.4813 - accuracy: 0.1405 - val_loss: 3.5318 - val_accuracy: 0.1133\n",
      "Epoch 13/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.4608 - accuracy: 0.1427 - val_loss: 3.5287 - val_accuracy: 0.1244\n",
      "Epoch 14/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.4478 - accuracy: 0.1427 - val_loss: 3.5152 - val_accuracy: 0.1200\n",
      "Epoch 15/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.4301 - accuracy: 0.1481 - val_loss: 3.5021 - val_accuracy: 0.1244\n",
      "Epoch 16/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.4136 - accuracy: 0.1531 - val_loss: 3.4951 - val_accuracy: 0.1222\n",
      "Epoch 17/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.4006 - accuracy: 0.1556 - val_loss: 3.4956 - val_accuracy: 0.1244\n",
      "Epoch 18/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.3850 - accuracy: 0.1627 - val_loss: 3.4892 - val_accuracy: 0.1222\n",
      "Epoch 19/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.3677 - accuracy: 0.1689 - val_loss: 3.4865 - val_accuracy: 0.1267\n",
      "Epoch 20/50\n",
      "127/127 [==============================] - 14s 110ms/step - loss: 3.3570 - accuracy: 0.1701 - val_loss: 3.4852 - val_accuracy: 0.1244\n",
      "Epoch 21/50\n",
      "127/127 [==============================] - 15s 114ms/step - loss: 3.3415 - accuracy: 0.1694 - val_loss: 3.4771 - val_accuracy: 0.1311\n",
      "Epoch 22/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.3288 - accuracy: 0.1723 - val_loss: 3.4704 - val_accuracy: 0.1422\n",
      "Epoch 23/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.3133 - accuracy: 0.1788 - val_loss: 3.4776 - val_accuracy: 0.1400\n",
      "Epoch 24/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.3029 - accuracy: 0.1822 - val_loss: 3.4681 - val_accuracy: 0.1356\n",
      "Epoch 25/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.2890 - accuracy: 0.1877 - val_loss: 3.4690 - val_accuracy: 0.1378\n",
      "Epoch 26/50\n",
      "127/127 [==============================] - 14s 110ms/step - loss: 3.2739 - accuracy: 0.1904 - val_loss: 3.4603 - val_accuracy: 0.1356\n",
      "Epoch 27/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.2625 - accuracy: 0.1936 - val_loss: 3.4630 - val_accuracy: 0.1356\n",
      "Epoch 28/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.2466 - accuracy: 0.1960 - val_loss: 3.4626 - val_accuracy: 0.1467\n",
      "Epoch 29/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.2369 - accuracy: 0.1975 - val_loss: 3.4572 - val_accuracy: 0.1444\n",
      "Epoch 30/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.2236 - accuracy: 0.1993 - val_loss: 3.4573 - val_accuracy: 0.1556\n",
      "Epoch 31/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.2080 - accuracy: 0.2037 - val_loss: 3.4523 - val_accuracy: 0.1444\n",
      "Epoch 32/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.1966 - accuracy: 0.2049 - val_loss: 3.4448 - val_accuracy: 0.1556\n",
      "Epoch 33/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.1834 - accuracy: 0.2109 - val_loss: 3.4433 - val_accuracy: 0.1533\n",
      "Epoch 34/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.1715 - accuracy: 0.2146 - val_loss: 3.4503 - val_accuracy: 0.1444\n",
      "Epoch 35/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.1590 - accuracy: 0.2183 - val_loss: 3.4471 - val_accuracy: 0.1400\n",
      "Epoch 36/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.1448 - accuracy: 0.2225 - val_loss: 3.4357 - val_accuracy: 0.1422\n",
      "Epoch 37/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.1322 - accuracy: 0.2227 - val_loss: 3.4347 - val_accuracy: 0.1489\n",
      "Epoch 38/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.1229 - accuracy: 0.2274 - val_loss: 3.4373 - val_accuracy: 0.1556\n",
      "Epoch 39/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.1103 - accuracy: 0.2257 - val_loss: 3.4365 - val_accuracy: 0.1511\n",
      "Epoch 40/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.0953 - accuracy: 0.2333 - val_loss: 3.4302 - val_accuracy: 0.1467\n",
      "Epoch 41/50\n",
      "127/127 [==============================] - 14s 109ms/step - loss: 3.0865 - accuracy: 0.2385 - val_loss: 3.4351 - val_accuracy: 0.1533\n",
      "Epoch 42/50\n",
      "127/127 [==============================] - 14s 110ms/step - loss: 3.0767 - accuracy: 0.2360 - val_loss: 3.4319 - val_accuracy: 0.1511\n",
      "Epoch 43/50\n",
      "127/127 [==============================] - 14s 113ms/step - loss: 3.0641 - accuracy: 0.2435 - val_loss: 3.4414 - val_accuracy: 0.1444\n",
      "Epoch 44/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.0513 - accuracy: 0.2425 - val_loss: 3.4196 - val_accuracy: 0.1578\n",
      "Epoch 45/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 3.0359 - accuracy: 0.2437 - val_loss: 3.4246 - val_accuracy: 0.1578\n",
      "Epoch 46/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.0276 - accuracy: 0.2454 - val_loss: 3.4226 - val_accuracy: 0.1556\n",
      "Epoch 47/50\n",
      "127/127 [==============================] - 14s 108ms/step - loss: 3.0176 - accuracy: 0.2511 - val_loss: 3.4242 - val_accuracy: 0.1511\n",
      "Epoch 48/50\n",
      "127/127 [==============================] - 13s 106ms/step - loss: 3.0041 - accuracy: 0.2546 - val_loss: 3.4260 - val_accuracy: 0.1467\n",
      "Epoch 49/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 2.9968 - accuracy: 0.2563 - val_loss: 3.4179 - val_accuracy: 0.1444\n",
      "Epoch 50/50\n",
      "127/127 [==============================] - 14s 107ms/step - loss: 2.9820 - accuracy: 0.2551 - val_loss: 3.4146 - val_accuracy: 0.1511\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train, y=y_train, epochs=50, shuffle=True,\n",
    "                    batch_size=32, validation_data=(X_val, y_val), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d960c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{model_name}-history\", \"wb\") as file:\n",
    "    pickle.dump(history, file)\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f356eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_pred.argmax(axis=-1).flatten(),y_test.argmax(axis=-1).flatten()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
